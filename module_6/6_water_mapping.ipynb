{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXpISJ1PjX88"
      },
      "source": [
        "# Module 6 - Mapping water from satellites"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/DHI/Intro_ML_course/blob/main/module_6/6_water_mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "eWtUilc8OFec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this module, we will explore the fascinating world of remote sensing using Sentinel-2 satellite imagery. Our focus will be on mapping water using different bands of light over the Brahmaputra river."
      ],
      "metadata": {
        "id": "Oas598YglKtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random\n",
        "import os\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "UXul8SgrlMUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_WECHfwjX8-"
      },
      "source": [
        "\n",
        "Satellite imagery has become an invaluable tool in various fields, providing a unique perspective on our planet from above. One of the remarkable features of satellite technology is its ability to capture light beyond the visible spectrum that the human eye can perceive. Infrared (IR) is one such type of radiation that satellites like Sentinel-2 can detect.\n",
        "\n",
        "Infrared can reveal information about surface temperatures, vegetation health, and even atmospheric conditions. For instance, healthy vegetation reflects more infrared light than unhealthy or non-vegetative surfaces."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Sentinel-2 satellite images"
      ],
      "metadata": {
        "id": "Rbnbl9-2se8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the upcoming exercises, we'll explore Sentinel-2 imagery of the Brahmaputra river, utilizing both visible and infrared bands. This advanced technology allows us to gain insights into environmental patterns and changes that are often invisible to the naked eye."
      ],
      "metadata": {
        "id": "CVz4jYQhtFMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DHI/Intro_ML_course/main/module_6/Brahmaputra_images.zip\n",
        "!unzip Brahmaputra_images.zip"
      ],
      "metadata": {
        "id": "klrBeb6zsCYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-Pfc09vjX8_"
      },
      "outputs": [],
      "source": [
        "files = sorted([file for file in os.listdir('.') if file.endswith('.npy')])\n",
        "images = [np.load(os.path.join('.', file)).astype('float') for file in files]\n",
        "images = [np.moveaxis(image, source=0, destination=-1) for image in images]\n",
        "images = [np.clip(image, 0, 1) for image in images]\n",
        "print('There are', len(images), 'images of shape:', images[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image has the following shape (1009, 1014, 4):\n",
        "- 1009 pixels high (around 10 kilometers)\n",
        "- 1014 pixels wide (around 10 kilometers)\n",
        "- 4 spectral bands: blue, green, red, near-infrared  \n",
        "\n",
        "These four bands are only a selection, this satellite records information for 11 wavelengths. Here we only selected blue, green, red and infrared."
      ],
      "metadata": {
        "id": "8pS2gvUeuJ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visualize satellite imagery"
      ],
      "metadata": {
        "id": "Akq2YvJM2F1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In natural colors\n",
        "\n",
        "To begin our exploration, we'll visualize the Sentinel-2 image in natural color. Natural color images represent the scene as it would appear to the human eye – using red, green, and blue channels. These channels capture the visible spectrum of light.\n",
        "\n",
        "We use the red channel to represent the red light, the green channel for green light, and the blue channel for blue light. This combination provides a true-to-life depiction of the landscape."
      ],
      "metadata": {
        "id": "yH16llwy2RlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgb = (2, 1, 0) # red, green, blue bands"
      ],
      "metadata": {
        "id": "6xxYQx6W3ShK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2aKrOdZjX8_"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "      index = i * 2 + j\n",
        "      axes[i, j].imshow(images[index][:, :, rgb])\n",
        "      axes[i, j].set_title(f'Date: {files[index][12:22]}')\n",
        "      axes[i, j].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In false colors\n",
        "\n",
        "Now, let's explore the concept of false color imagery using Sentinel-2 data. In false color images, different bands are assigned to specific color channels to highlight features that may not be visible in natural color. A common combination is using the near-infrared (NIR) band, the red band, and the blue band.\n",
        "\n",
        "The near-infrared band is particularly useful for vegetation analysis. In this combination, healthy vegetation appears bright red, while non-vegetative surfaces take on different colors. This visualization technique enhances the contrast of land cover types and unveils patterns that may not be apparent in visible light."
      ],
      "metadata": {
        "id": "raQfk4qx2vR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "false_colors = (3, 2, 0) # infrared, red, blue bands"
      ],
      "metadata": {
        "id": "t-4sms0d3U-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "      index = i * 2 + j\n",
        "      axes[i, j].imshow(images[index][:, :, false_colors])\n",
        "      axes[i, j].set_title(f'Date: {files[index][12:22]}')\n",
        "      axes[i, j].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Et7xCxU3fSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how simpler it is to differentiate vegetation, soil and water in false colors!"
      ],
      "metadata": {
        "id": "L8dfgZ_G3lhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Clusters of pixels"
      ],
      "metadata": {
        "id": "8qc6CbY82TIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've visualized the image in different color spaces, we'll take a closer look at specific bands – red and infrared. This step involves creating a scatter plot where each pixel's red reflectance is plotted on the x-axis, and infrared reflectance on the y-axis."
      ],
      "metadata": {
        "id": "ntiaBbyimTqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the images into tabular data\n",
        "\n",
        "Each row of the resuting table will correspond to one pixel for one date. For instance, the first row is pixel (1, 1) on 22nd of February 2022.\n",
        "\n",
        "Each column will correspond to the intensity of a spectral band (blue, green, red or near infrared)."
      ],
      "metadata": {
        "id": "TI6PIgRt4hru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the images into a long table\n",
        "data = np.array(images).reshape(-1, 4)\n",
        "data.shape"
      ],
      "metadata": {
        "id": "dKKMwlUv4DGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We select a small random subset of these 4 millions of data points for visualization."
      ],
      "metadata": {
        "id": "l0RQXhUo5lOj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw7AWY-ljX9B"
      },
      "outputs": [],
      "source": [
        "# we select only a random subset of pixels to display\n",
        "sample_size = 100000\n",
        "random_indices = np.random.choice(data.shape[0], size=10000, replace=False)\n",
        "data_subset = data[random_indices]\n",
        "data_subset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the distributions of the red and infrared intensities in a scatterplot - each dot represents a pixel."
      ],
      "metadata": {
        "id": "igx3TDu1583W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9xYkfqjX9B"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.scatter(data_subset[:, 2], data_subset[:, 3], alpha=0.1)\n",
        "plt.xlabel('Red')\n",
        "plt.ylabel('Infrared')\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whKGVgPzjX9B"
      },
      "source": [
        "## 5. Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scatter plot helps us identify different clusters corresponding to water bodies, vegetation, and soil. Water tends to have low reflectance in both red and infrared, while vegetation exhibits high infrared but low red reflectance.\n",
        "\n",
        "\n",
        "We'll use a clustering technique called K-Means to automatically group pixels into these clusters. For more information about K-Means, you can look at the following resources:\n",
        "- [Google for Developers guide on clustering](https://developers.google.com/machine-learning/clustering/algorithm/run-algorithm)\n",
        "- [Scikit-learn user guide on clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means)"
      ],
      "metadata": {
        "id": "ItOa4aVB618z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H5ctTeMjX9B"
      },
      "outputs": [],
      "source": [
        "# Select a number of clusters\n",
        "num_clusters = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwbueWENjX9B"
      },
      "outputs": [],
      "source": [
        "# Fit the K-Means model to cluster the selected data\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "labels = kmeans.fit_predict(data_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyY3HI1yjX9C"
      },
      "outputs": [],
      "source": [
        "# Retrieve the K-Means cluster centroids\n",
        "cluster_centers = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-jvSaKRjX9C"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "colors = ['C0', 'C1', 'C2', 'C3', 'C4']\n",
        "for i in range(num_clusters):\n",
        "    # plot pixels in different colors\n",
        "    plt.scatter(data_subset[labels==i, 2], data_subset[labels==i, 3],\n",
        "                color=f'C{i}', alpha=0.1)\n",
        "    # plot cluster centers as stars\n",
        "    plt.scatter(cluster_centers[i, 2], cluster_centers[i, 3],\n",
        "                color=f'C{i}', s=200, marker='*',\n",
        "                edgecolors='white', label=f'Cluster {i}')\n",
        "plt.xlabel('Red')\n",
        "plt.ylabel('Infrared')\n",
        "plt.legend()\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs1XX6UtjX9C"
      },
      "outputs": [],
      "source": [
        "# Assign each pixel in the image to the nearest cluster centroid\n",
        "assigned_clusters = kmeans.predict(data)\n",
        "\n",
        "# Reshape the assigned clusters to the shape of the original image\n",
        "assigned_clusters = assigned_clusters.reshape((4,) + images[0].shape[:2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assigned_clusters.shape"
      ],
      "metadata": {
        "id": "ZEpM77cW80Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcvWxXkwjX9C"
      },
      "outputs": [],
      "source": [
        "cluster_colors = [[0, 128, 255], [255, 153, 51], [0, 153, 0],\n",
        " [204, 0, 0], [150, 0, 180]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwFuI_HkjX9C"
      },
      "outputs": [],
      "source": [
        "# Use the assigned clusters and calculated colors to create an annotated image\n",
        "annotated_image = np.zeros(assigned_clusters.shape + (3, ),  dtype=np.uint8)\n",
        "for cluster_id in range(num_clusters):\n",
        "    annotated_image[assigned_clusters == cluster_id] = cluster_colors[cluster_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln0SUzHmjX9C"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize=(11, 6))\n",
        "for i in range(4):\n",
        "    axes[0, i].imshow(images[i][:, :, false_colors])\n",
        "    axes[0, i].set_title(files[i][12:22])\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].imshow(annotated_image[i])\n",
        "    axes[1, i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**: what happens if you decrease or increase `n_clusters` ?"
      ],
      "metadata": {
        "id": "hlFBtcZYPqQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Water mapping"
      ],
      "metadata": {
        "id": "SX-3Uj0m-3Lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the clusters correspond to water."
      ],
      "metadata": {
        "id": "vATR5A-a-7md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7a77AnfjX9C"
      },
      "outputs": [],
      "source": [
        "# select the number of the cluster which corresponds to water\n",
        "water_cluster = _ # Change the '_' to a number between 0 and 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IjmZq5wjX9C"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize=(11, 6))\n",
        "for i in range(4):\n",
        "    axes[0, i].imshow(images[i][:, :, false_colors])\n",
        "    axes[0, i].set_title(files[i][12:22])\n",
        "    axes[0, i].axis('off')\n",
        "    axes[1, i].imshow(assigned_clusters[i]==water_cluster, cmap='Blues')\n",
        "    axes[1, i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ImCi2OjX9D"
      },
      "source": [
        "#### **Exercise**: Find out what areas are always flooded, which ones are always dry and which ones vary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Second notebook**"
      ],
      "metadata": {
        "id": "v_pcsCfFAKFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/DHI/Intro_ML_course/blob/main/module_6/6_convolutional_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "7cXwfHILPMob"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 (DHI GRAS)",
      "language": "python",
      "name": "py3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}