{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4R5F_I0x4nu"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "The purpose of this assignment is to test that you have met the learning objectives of \"Intro to Machine Learning for Water Professionals\". In the first three modules of the course we have outlined the \"ML workflow\" shown in the image below, and put it into practice with common algorithms for classification and regression purposes.\n",
        "\n",
        "![ML_in_practice](https://raw.githubusercontent.com/DHI/Intro_ML_course/main/Assignment/ML_in_practice.PNG)\n",
        "\n",
        "In this assignment you are provided with a large dataset of hydrological data and asked to build a model to predict the average annual discharge of rivers. You will need to proceed iteratively, and gradually improve your model based on what you have learned in the previous iteration.\n",
        "\n",
        "To simplify your task, we have collected the data for you and we show a first simple iteration. Also, we have split the dataset in training, validation and testing. The validation dataset can be used to compare different algorithms and sets of hyperparameters, and therefore optimize your model. The testing dataset will be used for an unbiased assessment of your model performance. We will not distribute the test labels and we will use them to score and rank your predictions.\n",
        "\n",
        "There will be two scoring rounds. The first one during module 5 (submission by November 19th) and final one during module 6 (submission by November 26th). More information on the submission and scoring processes will be provided in due time. You will need to submit your predictions at least once to pass the course and earn your certificate.\n",
        "\n",
        "Please refer to the text below for more informaition on the avalable data and the problem to be solved. You will receive additional guidance and suggestions in the next live sessions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvXHrUApx4nz"
      },
      "source": [
        "**Load libraries and data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0urgFOcx4n0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv('https://github.com/DHI/Intro_ML_course/raw/main/Assignment/assignment_train.csv')\n",
        "df_val = pd.read_csv('https://github.com/DHI/Intro_ML_course/raw/main/Assignment/assignment_val.csv')\n",
        "df_test = pd.read_csv('https://github.com/DHI/Intro_ML_course/raw/main/Assignment/assignment_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUovMCXpx4n2",
        "outputId": "463b031f-20b6-4d32-c49b-9c9eace6bcdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30962, 34), (4251, 34), (8966, 33))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPl8tF5Yx4n3"
      },
      "source": [
        "As you can deduce from the shape of the datasets, the train data contains a much larger number of instances (rivers) than the validation and test subsets. In the image below you can see the geographical distribution of instances.\n",
        "\n",
        "You can also notice that the three subsets are randomly distributed across the planet, but we don't use instances from the same river basin in separate subsets. This would contaminate the subsets, as rivers from the same basin are expected to have very similar behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbiHG9Vux4n4"
      },
      "source": [
        "![assignment_dataset.jpeg](https://raw.githubusercontent.com/DHI/Intro_ML_course/main/Assignment/assignment_dataset.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRJj2KiLx4n4"
      },
      "source": [
        "**Explanation of features**\n",
        "\n",
        "The target variable is the average annual discharge expressed in $m^3/s$ ('dis_m3_pyr').\n",
        "\n",
        "Two of the input features are derived from the HydroRIVERS database (https://www.hydrosheds.org/products/hydrorivers), the remaining from the RiverAtlas database (https://www.hydrosheds.org/hydroatlas). Please refer to this catalog for a detailed explanation of the RiverAtlas features (https://github.com/DHI/Intro_ML_course/blob/main/Assignment/RiverATLAS_Catalog_v10.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target variable**\n",
        "\n",
        "```\n",
        "'dis_m3_pyr', # Average annual discharge in m3/s\n",
        "```\n",
        "\n",
        "**Input variables from HydroRIVERS**\n",
        "```\n",
        "'DIST_UP_KM', #  Distance to the most upstream location along the river network\n",
        "'UPLAND_SKM', # Drainage area in km2\n",
        "```\n",
        "\n",
        "**Coordinates**\n",
        "```\n",
        "'lon', 'lat'\n",
        "```\n",
        "\n",
        "\n",
        "**Input variables from RiverAtlas**\n",
        "\n",
        "*Hydrology* - Inundation extent, lake volume, reservoir volume and groundwater table depth\n",
        "```\n",
        "'inu_pc_umx', 'lka_pc_use', 'lkv_mc_usu', 'gwt_cm_cav'\n",
        "```\n",
        "*Physiography* - Elevation, terrain slope\n",
        "```\n",
        "'ele_mt_cav', 'ele_mt_uav', 'slp_dg_cav', 'slp_dg_uav'\n",
        "```\n",
        "*Climate* - Temperature max/min, precipitation, ET, aridity, moisture, snow cover\n",
        "```\n",
        "'tmp_dc_cmx', 'tmp_dc_cmn', 'pre_mm_uyr', 'pet_mm_uyr',\n",
        "'aet_mm_uyr', 'ari_ix_uav', 'cmi_ix_uyr', 'snw_pc_uyr'\n",
        "```\n",
        "*Land cover* - Forest, cropland, pasture and glacier extents\n",
        "```\n",
        "'for_pc_use', 'crp_pc_use', 'pst_pc_use', 'gla_pc_use'\n",
        "```\n",
        "*Soils* - Clay, silt, sand, organic carbon, water content\n",
        "```\n",
        "'cly_pc_uav', 'slt_pc_uav', 'snd_pc_uav', 'soc_th_uav', 'swc_pc_uyr'\n",
        "```\n",
        "*Anthropogenic* - Population density in catchment and upstram, GDP, human dev. index\n",
        "```\n",
        "'ppd_pk_cav', 'ppd_pk_uav', 'gdp_ud_cav', 'hdi_ix_cav'\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PgHwoOnI2tUx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRMGGZXix4n6"
      },
      "source": [
        "**Iteration 0**\n",
        "\n",
        "We start with a simple regression model given only two input features. Your goal is to train a model with a better performance on the validation dataset, finding a good tradeoff between underfitting and overfitting.\n",
        "\n",
        "When you are happy with your result, you should apply your trained model to make predictions for the test dataset. Notice that you are not provided with the test labels, so you are not able to assess the model performance on the test data. We will do that for you and return a quantitative feedback. Make sure the test predictions you share with us are expressed in the original measuring unit and scale.\n",
        "\n",
        "We will provide instructions on the submission of the test predictions in module 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40SIeRH8x4n6"
      },
      "outputs": [],
      "source": [
        "# Define the features (X) and the target variable (y) for training data\n",
        "X_train = df_train[['UPLAND_SKM', 'DIST_UP_KM']]\n",
        "y_train = df_train['dis_m3_pyr']\n",
        "\n",
        "# Define the features (X) and the target variable (y) for validation data\n",
        "X_val = df_val[['UPLAND_SKM', 'DIST_UP_KM']]\n",
        "y_val = df_val['dis_m3_pyr']\n",
        "\n",
        "# Define the features (X) for testing data\n",
        "X_test = df_test[['UPLAND_SKM', 'DIST_UP_KM']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBJ0WS2Ox4n7"
      },
      "outputs": [],
      "source": [
        "# Initialize linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable for the validation data\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Calculate the RMSE for the validation data\n",
        "mse = mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"RMSE validation: {rmse} m3/s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb7G7Fs8x4n7"
      },
      "outputs": [],
      "source": [
        "# Predict the target variable for the testing data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Export the predictions as a CSV file\n",
        "pd.DataFrame(y_test_pred).to_csv(\"assignment_test_predictions.csv\", index=False, header=False) # be mindful of where the file is saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiKrAhwCx4n8"
      },
      "source": [
        "**Iteration 1**\n",
        "\n",
        "It's your turn now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue6ztsk7x4n8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "keras",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
