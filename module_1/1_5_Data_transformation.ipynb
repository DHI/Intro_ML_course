{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "\n",
    "Data transformation is a crucial step in the preprocessing pipeline when preparing data for machine learning models. Properly transformed data can lead to models that converge faster and produce more accurate results.\n",
    "\n",
    "In this module we will cover the most common types of transformations you can apply to your data, namely normalization, standardization and one-hot encoding. We will continue using the \"large rivers\" dataset as example, and use methods contained in the *scikit-learn* library (often abbreviated as *sklearn*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load libraries and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe from xlsx file\n",
    "file_url = 'https://github.com/DHI/Intro_ML_course/raw/main/module_1/large_rivers_processed.csv'\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# If you are unable to read the file from the url, you can download it and read it locally\n",
    "# file_path = 'large_rivers_processed.csv'\n",
    "# df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Normalization (or Min-Max Scaling)**\n",
    "\n",
    "This method scales features to lie between a given minimum and maximum value (often between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elevation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize elevation\n",
    "scaler = MinMaxScaler()\n",
    "df['Elevation_norm'] = scaler.fit_transform(df[['Elevation']])\n",
    "\n",
    "df['Elevation_norm'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two histograms as subplots with Elevation and Elevation normalized\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "df['Elevation'].plot.hist(ax=axes[0], bins=20)\n",
    "df['Elevation_norm'].plot.hist(ax=axes[1], bins=20)\n",
    "axes[0].set_title('Elevation')\n",
    "axes[1].set_title('Elevation Normalized [0,1]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore scaler data and reverse transform\n",
    "print('Min value: ', scaler.data_min_)\n",
    "print('Max value: ', scaler.data_max_)\n",
    "\n",
    "print('Middle of scaling range: ', scaler.data_min_ + (scaler.data_max_ - scaler.data_min_) / 2)\n",
    "print('Inverse transform of 0.5 = ', scaler.inverse_transform([[0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Standardization (or Z-score Normalization)**\n",
    "\n",
    "This scales features to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Standardization\n",
    "scaler = StandardScaler()\n",
    "df['Elevation_stand'] = scaler.fit_transform(df[['Elevation']])\n",
    "\n",
    "df['Elevation_stand'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two boxplots as subplots with Elevation and Elevation standardized\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "df['Elevation'].plot.box(ax=axes[0])\n",
    "df['Elevation_stand'].plot.box(ax=axes[1])\n",
    "axes[0].set_title('Elevation')\n",
    "axes[1].set_title('Elevation Standardized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Distribution change**\n",
    "Skewness is a measure of the asymmetry of the probability distribution. In other words, skewness can indicate whether the data points in a statistical series are skewed to one side of the average value.\n",
    "\n",
    "Some algorithms work best if the data is normally distributed (i.e., skewness = 0). We can change the original distribution, by applying one of the following transformations:\n",
    "- Logarithm: only for x>0\n",
    "- Square root: only for x>=0\n",
    "- Cubic root: also for x<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root transformation\n",
    "df['Elevation_sqrt'] = np.sqrt(df['Elevation'])\n",
    "\n",
    "# Cube root transformation\n",
    "df['Elevation_cbrt'] = np.cbrt(df['Elevation'])\n",
    "\n",
    "# Logarithmic transformation\n",
    "df['Elevation_log'] = np.log(df['Elevation'])\n",
    "\n",
    "# Plot four histograms as subplots with original Elevation distribution and transformed versions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "df['Elevation'].plot.hist(ax=axes[0, 0], bins=30)\n",
    "df['Elevation_sqrt'].plot.hist(ax=axes[0, 1], bins=30)\n",
    "df['Elevation_cbrt'].plot.hist(ax=axes[1, 0], bins=30)\n",
    "df['Elevation_log'].plot.hist(ax=axes[1, 1], bins=30)\n",
    "axes[0, 0].set_title('Elevation')\n",
    "axes[0, 1].set_title('Elevation Square Root')\n",
    "axes[1, 0].set_title('Elevation Cube Root')\n",
    "axes[1, 1].set_title('Elevation Logarithmic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute skewness of Elevation and transformed versions\n",
    "print('Skewness of Elevation: ', df['Elevation'].skew())\n",
    "print('Skewness of Elevation Square Root: ', df['Elevation_sqrt'].skew())\n",
    "print('Skewness of Elevation Cube Root: ', df['Elevation_cbrt'].skew())\n",
    "print('Skewness of Elevation Logarithmic: ', df['Elevation_log'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.5**\n",
    "\n",
    "Find transformation that minimizes skewness of Discharge and visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. One-Hot Encoding**\n",
    "\n",
    "One-Hot Encoding converts categorical data into a binary matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print beginning of Name and Continent columns\n",
    "df[['Name', 'Continent']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply One-Hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df[['Continent']])\n",
    "\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add encoded data to dataframe with column names equal to encoder categories and river names as index\n",
    "df_encoded = pd.DataFrame(encoded_data, columns=encoder.categories_[0], index=df['Name'])\n",
    "df_encoded.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
